services:
# this is the comfy service, any kind of existing comfy container could be used
  comfyui:
    image: ghcr.io/lonelyowl13/comfy_simple:latest
    ports:
      - "127.0.0.1:8188:8188"
    volumes:
      - ./models/:/ComfyUI/models/
      - ./custom_nodes/:/ComfyUI/custom_nodes/
      - ./output:/ComfyUI/output
      - ./input:/ComfyUI/input
      - ./my_workflows:/ComfyUI/my_workflows
      - ./ComfyUI_temp:/ComfyUI_temp
      - ./comfyui.log:/ComfyUI/comfyui.log
      - ./venv:/venv

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]
              count: all

  # this is an api-wrapper service, it runs in a separate container
  api:
    image: comfy-api
    ports:
      - "127.0.0.1:3000:3000"
    volumes:
      - ./models:/models
      - ./output:/output
      - ./input:/inputs
      - ./workflows:/workflows
    depends_on:
      comfyui:
        condition: service_started
    build:
      context: . 
    environment:
      - DIRECT_ADDRESS=comfyui
    command: ["./comfyui-api"]

